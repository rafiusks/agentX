use agentx::config::{AgentXConfig, ProviderType};
use anyhow::Result;

#[tokio::main]
async fn main() -> Result<()> {
    println!("Testing AgentX configuration system...\n");
    
    // Load or create default configuration
    let mut config = AgentXConfig::load()?;
    
    println!("ğŸ“‹ Current Configuration:");
    println!("  Default Provider: {}", config.default_provider);
    println!("  Default Model: {}", config.default_model);
    println!("  Show Model Selector: {}", config.ui.show_model_selector);
    println!("  Auto Streaming: {}", config.ui.auto_stream);
    
    println!("\nğŸ¤– Available Models:");
    let models = config.list_available_models();
    for (i, (model_key, model)) in models.iter().enumerate() {
        let current = if model_key == &format!("{}/{}", config.default_provider, config.default_model) {
            " â† CURRENT"
        } else {
            ""
        };
        
        println!("  {}. {} - {}{}", 
            i + 1, 
            model.display_name,
            model.description.as_deref().unwrap_or("No description"),
            current
        );
        println!("     Provider: {}", model_key.split('/').next().unwrap_or("unknown"));
        println!("     Context Size: {} tokens", model.context_size);
        println!("     Streaming: {}", if model.supports_streaming { "âœ…" } else { "âŒ" });
        println!();
    }
    
    println!("ğŸ”§ Provider Details:");
    for (name, provider) in &config.providers {
        let status = match provider.provider_type {
            ProviderType::Ollama => {
                if provider.base_url.contains("localhost") {
                    "ğŸŸ¡ Local (may not be running)"
                } else {
                    "ğŸŸ¢ Remote"
                }
            }
            ProviderType::OpenAI | ProviderType::Anthropic => {
                if provider.api_key.is_some() {
                    "ğŸŸ¢ Configured"
                } else {
                    "ğŸ”´ API key required"
                }
            }
            ProviderType::OpenAICompatible => "ğŸŸ¡ Compatible endpoint"
        };
        
        println!("  {} ({})", provider.name, name);
        println!("    URL: {}", provider.base_url);
        println!("    Status: {}", status);
        println!("    Models: {}", provider.models.len());
        println!();
    }
    
    // Test model switching
    println!("ğŸ”„ Testing model switching...");
    let original_model = config.default_model.clone();
    
    // Find a different model to switch to
    if let Some((test_key, _)) = models.iter().find(|(key, _)| !key.ends_with(&original_model)) {
        let parts: Vec<&str> = test_key.split('/').collect();
        if parts.len() == 2 {
            println!("  Switching to: {}", test_key);
            config.set_default_model(parts[0].to_string(), parts[1].to_string())?;
            println!("  âœ… Switched successfully!");
            
            // Switch back
            let original_key = format!("{}/{}", config.default_provider, original_model);
            let parts: Vec<&str> = original_key.split('/').collect();
            config.set_default_model(parts[0].to_string(), parts[1].to_string())?;
            println!("  â†©ï¸  Switched back to original model");
        }
    }
    
    println!("\nğŸ“ Configuration saved to: ~/.config/agentx/config.toml");
    println!("ğŸ’¡ You can edit this file to customize providers and models");
    
    Ok(())
}